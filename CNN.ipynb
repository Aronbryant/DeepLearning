{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络做mnist识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#实例化一个小型卷积神经网络来进行手写数字识别\n",
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),input_shape=(28,28,1),activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到每一个卷积层和池化层的输出都是3D张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation = 'relu'))\n",
    "model.add(layers.Dense(10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "我们将进行10类别分类，最后一层使用带有十个输出的softmax函数激活，网络架构如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('D:\\\\data\\\\mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_test', 'x_train', 'y_train', 'y_test']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data['x_train']\n",
    "x_test = data['x_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = x_train.reshape((60000,28,28,1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = x_test.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(y_train)\n",
    "test_labels = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 35s 38ms/step - loss: 0.1618 - accuracy: 0.9493\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 32s 34ms/step - loss: 0.0460 - accuracy: 0.9858\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0323 - accuracy: 0.99000s - loss: 0.0323 - \n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 32s 34ms/step - loss: 0.0186 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d8b8b6fda0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(train_images,train_labels,epochs = 5,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9887999892234802"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss,test_acc = model.eva\n",
    "\n",
    "luate(test_images,test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到测试精度达到了98.88%，是相当不错的一个效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用torch搭建CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61aed184c2d481297f3fc9f18868369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c308cefb584268a6c53da382acff57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc58acac2294d8ca84c897852745418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7e57e01a1646d79456b010afb1055b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss 0.12345499700200416 Train  Accuracy 0.960920842217484 Teat Loss 0.03420348084624562 Test Accuracy 0.9879351265822784\n",
      "Epoch 2 Train Loss 0.03286826295936644 Train  Accuracy 0.9899386993603412 Teat Loss 0.0334932597627041 Test Accuracy 0.9888251582278481\n",
      "Epoch 3 Train Loss 0.022676309614899883 Train  Accuracy 0.9931203358208955 Teat Loss 0.024670037635656582 Test Accuracy 0.9921875\n",
      "Epoch 4 Train Loss 0.017494460609160673 Train  Accuracy 0.994319696162047 Teat Loss 0.02609861117327708 Test Accuracy 0.991495253164557\n",
      "Epoch 5 Train Loss 0.012738488631069703 Train  Accuracy 0.996018789978678 Teat Loss 0.021987379674976205 Test Accuracy 0.9931764240506329\n",
      "Epoch 6 Train Loss 0.009330235840040639 Train  Accuracy 0.9969016524520256 Teat Loss 0.0213495620211481 Test Accuracy 0.9926819620253164\n",
      "Epoch 7 Train Loss 0.0075988515747341615 Train  Accuracy 0.9977845149253731 Teat Loss 0.020343484291440946 Test Accuracy 0.9942642405063291\n",
      "Epoch 8 Train Loss 0.006351963666287923 Train  Accuracy 0.998034381663113 Teat Loss 0.017198033027883884 Test Accuracy 0.9949564873417721\n",
      "Epoch 9 Train Loss 0.004364761409075801 Train  Accuracy 0.9987839818763327 Teat Loss 0.030156434523037148 Test Accuracy 0.9913963607594937\n",
      "Epoch 10 Train Loss 0.0027837063254685847 Train  Accuracy 0.9992004264392325 Teat Loss 0.02026574383908558 Test Accuracy 0.9942642405063291\n",
      "Epoch 11 Train Loss 0.002096852820061083 Train  Accuracy 0.9993670042643923 Teat Loss 0.018739248426395017 Test Accuracy 0.9950553797468354\n",
      "Epoch 12 Train Loss 0.0016180204850721849 Train  Accuracy 0.9995502398720683 Teat Loss 0.01700700871428409 Test Accuracy 0.9949564873417721\n",
      "Epoch 13 Train Loss 0.001023718598630202 Train  Accuracy 0.9998001066098081 Teat Loss 0.01754526342488875 Test Accuracy 0.9949564873417721\n",
      "Epoch 14 Train Loss 0.0006251454699023771 Train  Accuracy 0.999883395522388 Teat Loss 0.017891759304750524 Test Accuracy 0.9953520569620253\n",
      "Epoch 15 Train Loss 0.00023960732170771472 Train  Accuracy 0.999983342217484 Teat Loss 0.018294602970479194 Test Accuracy 0.9953520569620253\n",
      "Epoch 16 Train Loss 0.0001530884421453729 Train  Accuracy 0.999983342217484 Teat Loss 0.018455991524977348 Test Accuracy 0.995253164556962\n",
      "Epoch 17 Train Loss 0.0001399506142703096 Train  Accuracy 0.999983342217484 Teat Loss 0.018514394552949447 Test Accuracy 0.9947587025316456\n",
      "Epoch 18 Train Loss 0.0001184843312488305 Train  Accuracy 1.0 Teat Loss 0.018880949848511446 Test Accuracy 0.9955498417721519\n",
      "Epoch 19 Train Loss 8.288939560327247e-05 Train  Accuracy 1.0 Teat Loss 0.019433405624301243 Test Accuracy 0.9955498417721519\n",
      "Epoch 20 Train Loss 7.041681675471698e-05 Train  Accuracy 1.0 Teat Loss 0.019614677618011694 Test Accuracy 0.9951542721518988\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import mnist\n",
    "from torch import  nn\n",
    "from torch.autograd import Variable\n",
    "from torch import  optim\n",
    "from torchvision import transforms\n",
    " \n",
    "# 定义CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "                nn.Conv2d(1,16,kernel_size=3), # 16, 26 ,26\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(16,32,kernel_size=3),# 32, 24, 24\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2)) # 32, 12,12     (24-2) /2 +1\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "                nn.Conv2d(32,64,kernel_size=3), # 64,10,10\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "                nn.Conv2d(64,128,kernel_size=3),  # 128,8,8\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2))  # 128, 4,4\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(128 * 4 * 4,1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024,128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(128,10))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    " \n",
    " \n",
    "# 使用内置函数下载mnist数据集\n",
    "train_set = mnist.MNIST('./data',train=True,download=True)\n",
    "test_set = mnist.MNIST('./data',train=False)\n",
    " \n",
    "# 预处理=>将各种预处理组合在一起\n",
    "data_tf = transforms.Compose(\n",
    "                [transforms.ToTensor(),\n",
    "                 transforms.Normalize([0.5],[0.5])])\n",
    " \n",
    "train_set = mnist.MNIST('./data',train=True,transform=data_tf,download=True)\n",
    "test_set = mnist.MNIST('./data',train=False,transform=data_tf,download=True)\n",
    " \n",
    "train_data = DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_data = DataLoader(test_set,batch_size=128,shuffle=False)\n",
    " \n",
    "net = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),1e-1)\n",
    " \n",
    "nums_epoch = 20\n",
    " \n",
    "# 开始训练\n",
    "losses =[]\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    " \n",
    "for epoch in range(nums_epoch):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    net = net.train()\n",
    "    for img , label in train_data:\n",
    "        #img = img.reshape(img.size(0),-1) \n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        # 前向传播\n",
    "        out = net(img)\n",
    "        loss = criterion(out,label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "        # 计算分类的准确率\n",
    "        _,pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "       \n",
    "        train_acc += acc\n",
    "        \n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    # 测试集不训练\n",
    "    for img , label in test_data:\n",
    "        #img = img.reshape(img.size(0),-1)\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        out = net(img)\n",
    "        \n",
    "        loss = criterion(out,label)\n",
    "        \n",
    "        # 记录误差\n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "        _ , pred = out.max(1)\n",
    "        num_correct = (pred==label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        \n",
    "        eval_acc += acc\n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    \n",
    "    print('Epoch {} Train Loss {} Train  Accuracy {} Teat Loss {} Test Accuracy {}'.format(\n",
    "        epoch+1, train_loss / len(train_data),train_acc / len(train_data), eval_loss / len(test_data), eval_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到最好的测试准确度达到了99.55%，效果非常好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
